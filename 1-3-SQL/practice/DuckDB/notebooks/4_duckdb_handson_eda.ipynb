{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4: Hands-on Exploratory Data Analysis with DuckDB :duck:**\n",
    "\n",
    "---\n",
    "\n",
    "By Jean-Yves Tran | jy.tran@[datascience-jy.com](https://datascience-jy.com) | [LinkedIn](https://www.linkedin.com/in/jytran-datascience/)  \n",
    "IBM Certified Data Analyst \n",
    "\n",
    "---\n",
    "\n",
    "Source: \n",
    "- [Getting Started with DuckDB](https://www.packtpub.com/en-ar/product/getting-started-with-duckdb-9781803232539) by Simon Aubury & Ned Letcher\n",
    "- [DuckDB documentation](https://duckdb.org/docs/)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive links in this notebook are not working due to GitHub limitations. View this notebook with the interactive links working [here](https://nbviewer.org/github/jendives2000/Data_ML_Practice_2025/blob/main/1-3-SQL/practice/DuckDB/notebooks/4_duckdb_handson_eda.ipynb).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part 3 of this series of notebooks on DuckDB.  \n",
    "For an introduction to DuckDB, check [my first notebook](https://github.com/jendives2000/Data_ML_Practice_2025/blob/82571ad44176666f9cf0735c5141c6a96d5eace9/1-3-SQL/practice/DuckDB/notebooks/1_duckdb_intro.ipynb). I also say in there when you should not use DuckDB. \n",
    "For understanding how DuckDB works, check my [second notebook](https://github.com/jendives2000/Data_ML_Practice_2025/blob/ef8533ad82586234cfdc54a494c0c5be590816cc/1-3-SQL/practice/DuckDB/notebooks/2_duckdb_python_API.ipynb).\n",
    "\n",
    "Here I will learn about best practices that:\n",
    "- save time when:\n",
    "  - [querying](#select-) or [inserting](#insert) data to a DuckDB database\n",
    "  - joining tables ([positional](#positional-joins) and [temporal joins](#temporal-joins-asof))\n",
    "\n",
    "<u>**SqlMagic:**</u>  \n",
    "\n",
    "You will notice starting from the insert chapter that I refactored a code that runs SQL commands from the DuckDB shell (CLI). I named it shell_commd(). \n",
    "There is a [better setup](https://duckdb.org/docs/guides/python/jupyter.html) for jupyter-based works that essentially:\n",
    "- runs SQL cells in Jupyter (using just '%sql' before any query) \n",
    "- and delivers the output as a pandas dataframe. \n",
    "\n",
    "Such a setup requires to install and import jupysql, pandas of course and optionally matplotlib and duck-engine.  \n",
    "I am **not using this setup** in this notebook but in the next one, which will be focused on data exploration and visualization. \n",
    "\n",
    "**OUTLINE:**  \n",
    "In more details, I will cover the followings:\n",
    "- [**Selecting columns**](#select-) effectively\n",
    "- Applying [**function chaining**](#function-chaining)\n",
    "- Using [**INSERT**](#insert) effectively\n",
    "- Leveraging [**positional** joins](#positional-joins) and [**temporal joins**](#temporal-joins-asof)\n",
    "- [**Recursive** queries](#hierarchical-traversal) and [macros](#macros)\n",
    "- additional **tips and tricks**\n",
    "\n",
    "**NICETIES:**  \n",
    "Some of the nicest little improvements brought by DuckDB are: \n",
    "- [trailing comma](#trailing-comma-is-fine) not a problem\n",
    "- the [exclude](#exclude-columns) clause\n",
    "- [visual bars](#visualize-bars-in-the-output) in the output\n",
    "- [insert or replace](#insert-or-replace)\n",
    "\n",
    "**SKIERS DATABASE**:  \n",
    "I added several very simple Skiers Database and csv files in the data/data_in folder: `skiers.csv`  \n",
    "They'll be used throughout this notebook. \n",
    "\n",
    "**The main takeaway is**:\n",
    "- to **better comprehend** the **differences** between regular SQL queries and DuckDB enhanced queries, which is often a lot less verbosity and more readability. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas matplotlib\n",
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Melbourne Pedestrian Count:\n",
    "\n",
    "I will be using a dataset made available by the city of Melbourne, Australia. contains hourly pedestrian counts from pedestrian sensors located in and around the Melbourne Central business district. We’ll be working with a historical timeframe of this dataset ranging from 2009 to 2022.\n",
    "\n",
    "I [imported](https://data.melbourne.vic.gov.au/api/datasets/1.0/pedestrian-counting-system-monthly-counts-per-hour/attachments/pedestrian_counting_system_monthly_counts_per_hour_may_2009_to_14_dec_2022_csv_zip/) it in the data/data_in folder. \n",
    "Once unzipped, this is:\n",
    "- a 420MB dataset \n",
    "- with over 2,1 million entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational API: \n",
    "\n",
    "I will use the Relational API because it offers more for what I will be doing: data exploratory analysis. \n",
    "\n",
    "Let's get our dataset into a Relational Object (RO from now on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬───────────────────────────────┬───────┬──────────┬───────┬──────────┬───────┬───────────┬───────────────────────────────┬───────────────┐\n",
      "│   ID    │           Date_Time           │ Year  │  Month   │ Mdate │   Day    │ Time  │ Sensor_ID │          Sensor_Name          │ Hourly_Counts │\n",
      "│  int64  │            varchar            │ int64 │ varchar  │ int64 │ varchar  │ int64 │   int64   │            varchar            │     int64     │\n",
      "├─────────┼───────────────────────────────┼───────┼──────────┼───────┼──────────┼───────┼───────────┼───────────────────────────────┼───────────────┤\n",
      "│ 2887628 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        34 │ Flinders St-Spark La          │           300 │\n",
      "│ 2887629 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        39 │ Alfred Place                  │           604 │\n",
      "│ 2887630 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        37 │ Lygon St (East)               │           216 │\n",
      "│ 2887631 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        40 │ Lonsdale St-Spring St (West)  │           627 │\n",
      "│ 2887632 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        36 │ Queen St (West)               │           774 │\n",
      "│ 2887633 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        29 │ St Kilda Rd-Alexandra Gardens │           644 │\n",
      "│ 2887634 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        42 │ Grattan St-Swanston St (West) │           453 │\n",
      "│ 2887635 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        43 │ Monash Rd-Swanston St (West)  │           387 │\n",
      "│ 2887636 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        44 │ Tin Alley-Swanston St (West)  │            27 │\n",
      "│ 2887637 │ November 01, 2019 05:00:00 PM │  2019 │ November │     1 │ Friday   │    17 │        35 │ Southbank                     │          2691 │\n",
      "│    ·    │               ·               │    ·  │    ·     │     · │   ·      │     · │         · │     ·                         │            ·  │\n",
      "│    ·    │               ·               │    ·  │    ·     │     · │   ·      │     · │         · │     ·                         │            ·  │\n",
      "│    ·    │               ·               │    ·  │    ·     │     · │   ·      │     · │         · │     ·                         │            ·  │\n",
      "│ 2897597 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        27 │ QV Market-Peel St             │           371 │\n",
      "│ 2897598 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        28 │ The Arts Centre               │          1188 │\n",
      "│ 2897599 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        31 │ Lygon St (West)               │           229 │\n",
      "│ 2897600 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        30 │ Lonsdale St (South)           │           391 │\n",
      "│ 2897601 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        34 │ Flinders St-Spark La          │           111 │\n",
      "│ 2897602 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        37 │ Lygon St (East)               │           133 │\n",
      "│ 2897603 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        40 │ Lonsdale St-Spring St (West)  │           154 │\n",
      "│ 2897604 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        36 │ Queen St (West)               │           249 │\n",
      "│ 2897605 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        29 │ St Kilda Rd-Alexandra Gardens │           448 │\n",
      "│ 2897606 │ November 09, 2019 10:00:00 AM │  2019 │ November │     9 │ Saturday │    10 │        42 │ Grattan St-Swanston St (West) │           288 │\n",
      "├─────────┴───────────────────────────────┴───────┴──────────┴───────┴──────────┴───────┴───────────┴───────────────────────────────┴───────────────┤\n",
      "│ ? rows (>9999 rows, 20 shown)                                                                                                          10 columns │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records = duckdb.read_csv(\"../data/data_in/pedestrian_records_2009-2022.csv\")\n",
    "\n",
    "# 200 is the max number of characters possible inside an entry:\n",
    "records.show(max_width = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Looking at the Data**:\n",
    "\n",
    "Because this is an RO, DuckDB loaded 10,000 rows and this what it **lazily returned** us here. There more entries than these 10,000. \n",
    "\n",
    "Lots of info in this dataset: \n",
    "- **count of pedestrians** detected by \n",
    "- a specific **sensor** \n",
    "- during **each hour**. \n",
    "- Additionally, it provides other details related to the hourly readings, including the **sensor name** \n",
    "  - and the **timestamp**, along with date and time components derived from the timestamp.\n",
    "\n",
    "### **Data types**:\n",
    "Notice in the header of the output that datetime is of the data type VARCHAR, meaning text. It should be a timestamp (docs on this [here](http://duckdb.org/docs/sql/functions/dateformat)). Let's fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = duckdb.read_csv(\n",
    "    \"../data/data_in/pedestrian_records_2009-2022.csv\",\n",
    "    dtype={\"Date_Time\": \"TIMESTAMP\"},\n",
    "    timestamp_format=\"%B %d, %Y %H:%M:%S %p\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm this change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬─────────────────────┬───────┬──────────┬───────┬─────────┬───────┬───────────┬──────────────────────────────┬───────────────┐\n",
      "│   ID    │      Date_Time      │ Year  │  Month   │ Mdate │   Day   │ Time  │ Sensor_ID │         Sensor_Name          │ Hourly_Counts │\n",
      "│  int64  │      timestamp      │ int64 │ varchar  │ int64 │ varchar │ int64 │   int64   │           varchar            │     int64     │\n",
      "├─────────┼─────────────────────┼───────┼──────────┼───────┼─────────┼───────┼───────────┼──────────────────────────────┼───────────────┤\n",
      "│ 2887628 │ 2019-11-01 17:00:00 │  2019 │ November │     1 │ Friday  │    17 │        34 │ Flinders St-Spark La         │           300 │\n",
      "│ 2887629 │ 2019-11-01 17:00:00 │  2019 │ November │     1 │ Friday  │    17 │        39 │ Alfred Place                 │           604 │\n",
      "│ 2887630 │ 2019-11-01 17:00:00 │  2019 │ November │     1 │ Friday  │    17 │        37 │ Lygon St (East)              │           216 │\n",
      "│ 2887631 │ 2019-11-01 17:00:00 │  2019 │ November │     1 │ Friday  │    17 │        40 │ Lonsdale St-Spring St (West) │           627 │\n",
      "│ 2887632 │ 2019-11-01 17:00:00 │  2019 │ November │     1 │ Friday  │    17 │        36 │ Queen St (West)              │           774 │\n",
      "└─────────┴─────────────────────┴───────┴──────────┴───────┴─────────┴───────┴───────────┴──────────────────────────────┴───────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records.limit(5).show(max_width=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Enums for low cardinality String Columns**:\n",
    "\n",
    "ENUM types are a way to **convert string values into numbers** in a database. This is useful for columns with a limited number of different values, like month names and days of the week. By using ENUMs for these columns, we can **save storage space** and **speed up queries** because the database only stores numbers instead of full strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
