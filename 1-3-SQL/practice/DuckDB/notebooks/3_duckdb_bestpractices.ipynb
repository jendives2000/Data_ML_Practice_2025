{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3: DuckDB's Best Practices**\n",
    "\n",
    "---\n",
    "\n",
    "By Jean-Yves Tran | jy.tran@[datascience-jy.com](https://datascience-jy.com) | [LinkedIn](https://www.linkedin.com/in/jytran-datascience/)  \n",
    "IBM Certified Data Analyst \n",
    "\n",
    "---\n",
    "\n",
    "Source: \n",
    "- [Getting Started with DuckDB](https://www.packtpub.com/en-ar/product/getting-started-with-duckdb-9781803232539) by Simon Aubury & Ned Letcher\n",
    "- [DuckDB documentation](https://duckdb.org/docs/)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive links in this notebook are not working due to GitHub limitations. View this notebook with the interactive links working [here](https://nbviewer.org/github/jendives2000/Data_ML_Practice_2025/blob/main/1-3-SQL/practice/DuckDB/notebooks/2_duckdb_python_API.ipynb).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part 3 of the series of notebooks on DuckDB.  \n",
    "In the previous two notebooks I've introduced DuckDB and shoed how to load, transform and briefly analyse data from different sources.  \n",
    "Here I will learn about best practices that:\n",
    "- save time when:\n",
    "  - querying or inserting data to a DuckDB database\n",
    "  - joining tables (positional and temporal joins)\n",
    "\n",
    "For an introduction to DuckDB, check [my first notebook](https://github.com/jendives2000/Data_ML_Practice_2025/blob/82571ad44176666f9cf0735c5141c6a96d5eace9/1-3-SQL/practice/DuckDB/notebooks/1_duckdb_intro.ipynb). I also say in there when you should not use DuckDB. \n",
    "\n",
    "For understanding how DuckDB works, check my [second notebook](https://github.com/jendives2000/Data_ML_Practice_2025/blob/ef8533ad82586234cfdc54a494c0c5be590816cc/1-3-SQL/practice/DuckDB/notebooks/2_duckdb_python_API.ipynb).\n",
    "\n",
    "In more details, I will cover the followings:\n",
    "- **Selecting columns** effectively\n",
    "- Applying **function chaining**\n",
    "- Using **INSERT** effectively\n",
    "- Leveraging **positional** joins and **temporal joins**\n",
    "- **Recursive** queries and macros\n",
    "- additional **tips and tricks**\n",
    "\n",
    "**SKIERS DATABASE**:  \n",
    "I added a very simple Skiers Database in the data/data_in folder: `skiers.csv`  \n",
    "It'll be used throughout this notebook. \n",
    "\n",
    "**The two main takeaways are**:\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to sys.path\n",
    "#sys.path.append(os.path.abspath(\"..\"))\n",
    "#from utils.duckdb_shared_code import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table setup using the DuckDB Shell:\n",
    "\n",
    "I want to work with the DuckDB shell, from my Jupyter notebook. It is possible by using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!duckdb ../databases/mydatabase.duckdb -c \"create or replace table skiers as select * from read_csv('../data/data_in/skiers.csv');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┐\n",
      "│  name   │\n",
      "│ varchar │\n",
      "├─────────┤\n",
      "│ skiers  │\n",
      "└─────────┘\n"
     ]
    }
   ],
   "source": [
    "!duckdb ../databases/mydatabase.duckdb -c \"show tables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refactor this syntax and copy it over to the `duckdb_shared_code.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shell_commd(stmt):\n",
    "    # Collapse all whitespace (including newlines) into single spaces\n",
    "    cleaned_stmt = \" \".join(stmt.split())\n",
    "    get_ipython().system(f\"duckdb ../databases/mydatabase.duckdb -c \\\"{cleaned_stmt}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select *:\n",
    "I want to see the whole table skiers now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────────┬───────────┬──────────────┬────────────────────┬─────────────────┐\n",
      "│ skier_first_name │ skier_last_name │ skier_age │ skier_height │ skier_helmet_color │ skier_bib_color │\n",
      "│     varchar      │     varchar     │   int64   │    int64     │      varchar       │     varchar     │\n",
      "├──────────────────┼─────────────────┼───────────┼──────────────┼────────────────────┼─────────────────┤\n",
      "│ Alice            │ Smith           │        12 │          152 │ red                │ black           │\n",
      "│ Bob              │ Blaese          │        16 │          178 │ blue               │ yellow          │\n",
      "│ Carol            │ Wilson          │        32 │          159 │ yellow             │ pink            │\n",
      "│ Dan              │ Jones           │        52 │          182 │ red                │ yellow          │\n",
      "│ Erin             │ Taylor          │        22 │          168 │ black              │ green           │\n",
      "│ Frank            │ Williams        │        18 │          187 │ yellow             │ red             │\n",
      "│ Grace            │ Miller          │        24 │          172 │ pink               │ black           │\n",
      "│ Heidi            │ Johnson         │        22 │          178 │ yellow             │ yellow          │\n",
      "│ Ivan             │ Brown           │        21 │          185 │ green              │ pink            │\n",
      "│ Judy             │ Moore           │        27 │          160 │ red                │ black           │\n",
      "├──────────────────┴─────────────────┴───────────┴──────────────┴────────────────────┴─────────────────┤\n",
      "│ 10 rows                                                                                    6 columns │\n",
      "└──────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select * \n",
    "    from skiers\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trailing comma is fine:  \n",
    "One little improvement that I appreciate is that a final trailing comma is not throwing an error.  \n",
    "I select multiple columns, and I forget to remove my last comma here `skier_bib_color,`, line 9: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────────┬───────────┬──────────────┬────────────────────┬─────────────────┐\n",
      "│ skier_first_name │ skier_last_name │ skier_age │ skier_height │ skier_helmet_color │ skier_bib_color │\n",
      "│     varchar      │     varchar     │   int64   │    int64     │      varchar       │     varchar     │\n",
      "├──────────────────┼─────────────────┼───────────┼──────────────┼────────────────────┼─────────────────┤\n",
      "│ Alice            │ Smith           │        12 │          152 │ red                │ black           │\n",
      "│ Bob              │ Blaese          │        16 │          178 │ blue               │ yellow          │\n",
      "│ Carol            │ Wilson          │        32 │          159 │ yellow             │ pink            │\n",
      "│ Dan              │ Jones           │        52 │          182 │ red                │ yellow          │\n",
      "│ Erin             │ Taylor          │        22 │          168 │ black              │ green           │\n",
      "│ Frank            │ Williams        │        18 │          187 │ yellow             │ red             │\n",
      "│ Grace            │ Miller          │        24 │          172 │ pink               │ black           │\n",
      "│ Heidi            │ Johnson         │        22 │          178 │ yellow             │ yellow          │\n",
      "│ Ivan             │ Brown           │        21 │          185 │ green              │ pink            │\n",
      "│ Judy             │ Moore           │        27 │          160 │ red                │ black           │\n",
      "├──────────────────┴─────────────────┴───────────┴──────────────┴────────────────────┴─────────────────┤\n",
      "│ 10 rows                                                                                    6 columns │\n",
      "└──────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select\n",
    "        skier_first_name,\n",
    "        skier_last_name,\n",
    "        skier_age,\n",
    "        skier_height,\n",
    "        skier_helmet_color,\n",
    "        skier_bib_color,\n",
    "    from skiers\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No problems, the last trailing comma is valid!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exclude columns**: \n",
    "\n",
    "What if I need every column but one? Normally I'd have to select each single column except for the one I don't want.  \n",
    "Now with EXCLUDE() I can just exclude the one column (or more) to get everything else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────────┬────────────────────┬─────────────────┐\n",
      "│ skier_first_name │ skier_last_name │ skier_helmet_color │ skier_bib_color │\n",
      "│     varchar      │     varchar     │      varchar       │     varchar     │\n",
      "├──────────────────┼─────────────────┼────────────────────┼─────────────────┤\n",
      "│ Alice            │ Smith           │ red                │ black           │\n",
      "│ Bob              │ Blaese          │ blue               │ yellow          │\n",
      "│ Carol            │ Wilson          │ yellow             │ pink            │\n",
      "│ Dan              │ Jones           │ red                │ yellow          │\n",
      "│ Erin             │ Taylor          │ black              │ green           │\n",
      "│ Frank            │ Williams        │ yellow             │ red             │\n",
      "│ Grace            │ Miller          │ pink               │ black           │\n",
      "│ Heidi            │ Johnson         │ yellow             │ yellow          │\n",
      "│ Ivan             │ Brown           │ green              │ pink            │\n",
      "│ Judy             │ Moore           │ red                │ black           │\n",
      "├──────────────────┴─────────────────┴────────────────────┴─────────────────┤\n",
      "│ 10 rows                                                         4 columns │\n",
      "└───────────────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select s.*\n",
    "    exclude(skier_age, skier_height)\n",
    "    from skiers as s\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dynamic Column Replacement**: \n",
    "\n",
    "Let's say I now want to round the skier_age to the nearest 10 years and convert them into integers, effectively changing its value and data type. The method REPLACE() helps do that kind of modifications: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────────┬───────────┬──────────────┬────────────────────┬─────────────────┐\n",
      "│ skier_first_name │ skier_last_name │ skier_age │ skier_height │ skier_helmet_color │ skier_bib_color │\n",
      "│     varchar      │     varchar     │   int32   │    int64     │      varchar       │     varchar     │\n",
      "├──────────────────┼─────────────────┼───────────┼──────────────┼────────────────────┼─────────────────┤\n",
      "│ Alice            │ Smith           │        10 │          152 │ red                │ black           │\n",
      "│ Bob              │ Blaese          │        20 │          178 │ blue               │ yellow          │\n",
      "│ Carol            │ Wilson          │        30 │          159 │ yellow             │ pink            │\n",
      "│ Dan              │ Jones           │        50 │          182 │ red                │ yellow          │\n",
      "│ Erin             │ Taylor          │        20 │          168 │ black              │ green           │\n",
      "│ Frank            │ Williams        │        20 │          187 │ yellow             │ red             │\n",
      "│ Grace            │ Miller          │        20 │          172 │ pink               │ black           │\n",
      "│ Heidi            │ Johnson         │        20 │          178 │ yellow             │ yellow          │\n",
      "│ Ivan             │ Brown           │        20 │          185 │ green              │ pink            │\n",
      "│ Judy             │ Moore           │        30 │          160 │ red                │ black           │\n",
      "├──────────────────┴─────────────────┴───────────┴──────────────┴────────────────────┴─────────────────┤\n",
      "│ 10 rows                                                                                    6 columns │\n",
      "└──────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select s.*\n",
    "        replace(\n",
    "            round(skier_age / 10) *10\n",
    "        )::integer \n",
    "        as skier_age\n",
    "    from skiers as s\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Column Selector**:\n",
    "\n",
    "I can also use the column selector COLUMNS() with a regular expression to, say, get columns that have the word 'color' in their name:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬────────────────────┬─────────────────┐\n",
      "│ skier_first_name │ skier_helmet_color │ skier_bib_color │\n",
      "│     varchar      │      varchar       │     varchar     │\n",
      "├──────────────────┼────────────────────┼─────────────────┤\n",
      "│ Alice            │ red                │ black           │\n",
      "│ Bob              │ blue               │ yellow          │\n",
      "│ Carol            │ yellow             │ pink            │\n",
      "│ Dan              │ red                │ yellow          │\n",
      "│ Erin             │ black              │ green           │\n",
      "│ Frank            │ yellow             │ red             │\n",
      "│ Grace            │ pink               │ black           │\n",
      "│ Heidi            │ yellow             │ yellow          │\n",
      "│ Ivan             │ green              │ pink            │\n",
      "│ Judy             │ red                │ black           │\n",
      "├──────────────────┴────────────────────┴─────────────────┤\n",
      "│ 10 rows                                       3 columns │\n",
      "└─────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select \n",
    "        skier_first_name,\n",
    "        columns(\n",
    "            '.*color$'\n",
    "        )\n",
    "    from skiers\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression `'.*color$'` matched 2 columns that have in their name the word color. \n",
    "\n",
    "I can take it one step further and filter it to get only one type of value from these columns, say the color yellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬────────────────────┬─────────────────┐\n",
      "│ skier_first_name │ skier_helmet_color │ skier_bib_color │\n",
      "│     varchar      │      varchar       │     varchar     │\n",
      "├──────────────────┼────────────────────┼─────────────────┤\n",
      "│ Heidi            │ yellow             │ yellow          │\n",
      "└──────────────────┴────────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select \n",
    "        skier_first_name,\n",
    "        columns(\n",
    "            '.*color.*'\n",
    "        )\n",
    "    from skiers\n",
    "    where columns('.*color.*') == 'yellow'\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Function Chaining**:\n",
    "\n",
    "I showed a glimpse of that feature in my previous notebook. It adds **readability** and also, for Python users among you, **usability**. \n",
    "\n",
    "The little exercise I am doing is as follows: \n",
    "- putting together the first and last name of skiers with the **`CONCAT_WS()` method**\n",
    "- make that full name in uppercase with **UPPER()**\n",
    "- add a filler, '_' that will push the full name to right edge of its column width, and make that width 20 units, with **`LPAD()`**\n",
    "- add a full stop '.' at the end\n",
    "\n",
    "### The naive way:  \n",
    "\n",
    "Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┐\n",
      "│      skier_name       │\n",
      "│        varchar        │\n",
      "├───────────────────────┤\n",
      "│ _________ALICE SMITH. │\n",
      "│ __________BOB BLAESE. │\n",
      "│ ________CAROL WILSON. │\n",
      "│ ___________DAN JONES. │\n",
      "│ _________ERIN TAYLOR. │\n",
      "│ ______FRANK WILLIAMS. │\n",
      "│ ________GRACE MILLER. │\n",
      "│ _______HEIDI JOHNSON. │\n",
      "│ __________IVAN BROWN. │\n",
      "│ __________JUDY MOORE. │\n",
      "├───────────────────────┤\n",
      "│        10 rows        │\n",
      "└───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select concat(\n",
    "        lpad(\n",
    "            upper(\n",
    "                concat_ws(' ', skier_first_name, skier_last_name)\n",
    "            ),\n",
    "            20,\n",
    "            '_'\n",
    "        ),\n",
    "        '.'\n",
    "    )\n",
    "    as skier_name\n",
    "    from skiers\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the way I laid out the code, this goes 3 indenting levels down, with hard to read text characters like '.' or '_'.  \n",
    "\n",
    "**NOTE**:  \n",
    "It is important to remember that that each function used here is what is called a scalar function. It returns only one value.  \n",
    "Chaining **ONLY** works with **scalar** functions. More [here](https://duckdb.org/docs/sql/functions/overview.html) on DuckDB's website.\n",
    "\n",
    "### **Correct way: method chaining**:\n",
    "Now let's see one of the correct way, with of course method chaining: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────────────┐\n",
      "│      skier_name       │\n",
      "│        varchar        │\n",
      "├───────────────────────┤\n",
      "│ _________ALICE SMITH. │\n",
      "│ __________BOB BLAESE. │\n",
      "│ ________CAROL WILSON. │\n",
      "│ ___________DAN JONES. │\n",
      "│ _________ERIN TAYLOR. │\n",
      "│ ______FRANK WILLIAMS. │\n",
      "│ ________GRACE MILLER. │\n",
      "│ _______HEIDI JOHNSON. │\n",
      "│ __________IVAN BROWN. │\n",
      "│ __________JUDY MOORE. │\n",
      "├───────────────────────┤\n",
      "│        10 rows        │\n",
      "└───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select concat_ws(' ', skier_first_name, skier_last_name)\n",
    "        .upper()\n",
    "        .lpad(20, '_')\n",
    "        .concat('.')\n",
    "        as skier_name\n",
    "    from skiers\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **insert**:\n",
    "\n",
    "As it is often needed, I want to have an index, here on the skiers, so that each skier's name is uniquelu identified if there is false duplicates (different persons but with the same full name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    create unique index skier_unique\n",
    "    on skiers (skier_first_name)\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's say that a new skier is added: Kim with a blue helmet. \n",
    "Here's the naive approach to insert Kim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    insert into skiers(\n",
    "        skier_first_name, \n",
    "        skier_helmet_color\n",
    "        )\n",
    "    select \n",
    "        'Kim' as skier_first_name,\n",
    "        'blue' as skier_helmet_color\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this syntax is not complex, I have to respect the order of what is inserted with what is selected. For bigger inserts this can potentially become very taxing. \n",
    "\n",
    "### **by name**:\n",
    "For that, I can use the `by name` directive. Let's use it to add Liam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    insert into skiers by name\n",
    "    select \n",
    "        'green' as skier_helmet_color,\n",
    "        'red' as skier_bib_color,\n",
    "        'Liam' as skier_first_name,\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Liam's insert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬────────────────────┬─────────────────┐\n",
      "│   sfn   │ skier_helmet_color │ skier_bib_color │\n",
      "│ varchar │      varchar       │     varchar     │\n",
      "├─────────┼────────────────────┼─────────────────┤\n",
      "│ Liam    │ green              │ red             │\n",
      "└─────────┴────────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select \n",
    "        skier_first_name as sfn,\n",
    "        skier_helmet_color,\n",
    "        skier_bib_color,\n",
    "    from skiers\n",
    "    where sfn = 'Liam'\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **insert or replace**:\n",
    "\n",
    "Liam just changed his helmet and it is now black. \n",
    "To update this, instead of manually checking for Liam's helmet row and changing it, I can just use the `insert or replace` clause. \n",
    "\n",
    "This avoids the need to use a `merge` or an `ON CONFLICT DO UPDATE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    insert or replace into skiers by name\n",
    "    select\n",
    "        'Liam' as skier_first_name,\n",
    "        'black' as skier_helmet_color\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i repeat the previous code I can see again Liam's details, updated: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬────────────────────┬─────────────────┐\n",
      "│   sfn   │ skier_helmet_color │ skier_bib_color │\n",
      "│ varchar │      varchar       │     varchar     │\n",
      "├─────────┼────────────────────┼─────────────────┤\n",
      "│ Liam    │ black              │ red             │\n",
      "└─────────┴────────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select \n",
    "        skier_first_name as sfn,\n",
    "        skier_helmet_color,\n",
    "        skier_bib_color,\n",
    "    from skiers\n",
    "    where sfn = 'Liam'\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **positional joins**:\n",
    "\n",
    "A positional join is a feature in DuckDB that looks at the ordering of 2 or more tables, no matter how different these ordering are. \n",
    "\n",
    "For example, our skiers are competing. Each skier competes and their name is added at the end of a file (skiers.csv). The judges' scores are inserted in the skiers_scores.csv file, starting from the top of the file and down. \n",
    "\n",
    "I start by replacing the skiers table with the table from the skiers.csv file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    create or replace table skiers as\n",
    "    select *\n",
    "    from read_csv('../data/data_in/skiers.csv')\n",
    "    ;    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imported the skiers' score file in the data/data_in folder. Let's create the score table from it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    create or replace table scores as\n",
    "    select *\n",
    "    from read_csv('../data/data_in/skier_scores.csv')\n",
    "    ;   \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So without DuckDB, these 2 tables are seen as **unordered**. Which means that another element is needed to do the orders matching.  \n",
    "DuckDB can see them as two dataframes and connects them with the `positional join` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────┬─────────────────┬───────┐\n",
      "│ skier_first_name │ skier_last_name │ score │\n",
      "│     varchar      │     varchar     │ int64 │\n",
      "├──────────────────┼─────────────────┼───────┤\n",
      "│ Alice            │ Smith           │     8 │\n",
      "│ Bob              │ Blaese          │     9 │\n",
      "│ Carol            │ Wilson          │     4 │\n",
      "│ Dan              │ Jones           │     7 │\n",
      "│ Erin             │ Taylor          │     6 │\n",
      "│ Frank            │ Williams        │     9 │\n",
      "│ Grace            │ Miller          │     9 │\n",
      "│ Heidi            │ Johnson         │     5 │\n",
      "│ Ivan             │ Brown           │     7 │\n",
      "│ Judy             │ Moore           │     8 │\n",
      "├──────────────────┴─────────────────┴───────┤\n",
      "│ 10 rows                          3 columns │\n",
      "└────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select\n",
    "        df_sk.skier_first_name,\n",
    "        df_sk.skier_last_name,\n",
    "        df_sc.score\n",
    "    from skiers \n",
    "        as df_sk positional join scores as df_sc\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **temporal joins: ASOF**\n",
    "\n",
    "To illustrate the use of ASOF we need some context. More data needs to be put together: \n",
    "- the wind speed\n",
    "- the temperature\n",
    "- at the time each skier got a score\n",
    "\n",
    "I could join each skier's score_time to the measurement_time_timestamp BUT this will not work because they are both different. For example:  \n",
    "- score time = 2023-12-01 10:01:28  \n",
    "- measurement_time_timestamp = 2023-12-01 10:00:00  \n",
    "\n",
    "The time measurement is hourly and automatic. Skiers' scores time are not automatic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **standard SQL way**:\n",
    "Let's look at one of the way to do this using standard SQL.  \n",
    "For that I imported the weather.csv file and I now need to create a table out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    create or replace table weather as\n",
    "    select *\n",
    "    from read_csv(\n",
    "        '../data/data_in/weather.csv',\n",
    "        timestampformat='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬────────────┬───────┐\n",
      "│  measurement_time   │ wind_speed │ temp  │\n",
      "│      timestamp      │   int64    │ int64 │\n",
      "├─────────────────────┼────────────┼───────┤\n",
      "│ 2023-12-01 10:00:00 │          7 │    -9 │\n",
      "│ 2023-12-01 11:00:00 │         19 │    -8 │\n",
      "│ 2023-12-01 12:00:00 │          8 │    -6 │\n",
      "│ 2023-12-01 13:00:00 │          9 │    -3 │\n",
      "│ 2023-12-01 14:00:00 │         10 │    -2 │\n",
      "│ 2023-12-01 15:00:00 │         10 │    -2 │\n",
      "│ 2023-12-01 16:00:00 │         12 │    -2 │\n",
      "│ 2023-12-01 17:00:00 │         12 │    -3 │\n",
      "│ 2023-12-01 18:00:00 │         12 │    -3 │\n",
      "│ 2023-12-01 19:00:00 │         11 │    -4 │\n",
      "├─────────────────────┴────────────┴───────┤\n",
      "│ 10 rows                        3 columns │\n",
      "└──────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from weather\n",
    "    limit 10\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬────────────┬───────┬─────────────────────┐\n",
      "│  measurement_time   │ wind_speed │ temp  │   measurement_end   │\n",
      "│      timestamp      │   int64    │ int64 │      timestamp      │\n",
      "├─────────────────────┼────────────┼───────┼─────────────────────┤\n",
      "│ 2023-12-01 10:00:00 │          7 │    -9 │ 2023-12-01 11:00:00 │\n",
      "└─────────────────────┴────────────┴───────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    with weather_cte as(\n",
    "        select measurement_time,\n",
    "        wind_speed, \n",
    "        temp,\n",
    "        lead(measurement_time, 1)\n",
    "            over (order by measurement_time) as measurement_end\n",
    "        from weather\n",
    "        order by measurement_time\n",
    "    )\n",
    "    select * \n",
    "    from weather_cte\n",
    "    where timestamp '2023-12-01 10:01:00'\n",
    "        between measurement_time and measurement_end\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot happening in this query, so let's analyze it step by step: \n",
    "- A common table expression (CTE) retrieves:\n",
    "  - data from the weather table, \n",
    "  - using the LEAD function to:\n",
    "    -  determine the next measurement_time, \n",
    "    -  sorted by measurement_time. \n",
    "-  I locate the weather for:\n",
    "   -  the timestamp 2023-12-01 10:01 \n",
    "   -  by filtering for the row that lies between the measurement_time and measurement_end columns.\n",
    "\n",
    "This can potentially get a lot more complex and lead to errors down the road. \n",
    "\n",
    "#### the ASOF DuckDB way:\n",
    "\n",
    "I use the ASOF now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬───────┬─────────────────────┬────────────┬───────┐\n",
      "│     score_time      │ score │  measurement_time   │ wind_speed │ temp  │\n",
      "│      timestamp      │ int64 │      timestamp      │   int64    │ int64 │\n",
      "├─────────────────────┼───────┼─────────────────────┼────────────┼───────┤\n",
      "│ 2023-12-01 10:01:00 │     8 │ 2023-12-01 10:00:00 │          7 │    -9 │\n",
      "│ 2023-12-01 10:42:00 │     9 │ 2023-12-01 10:00:00 │          7 │    -9 │\n",
      "│ 2023-12-01 11:24:00 │     4 │ 2023-12-01 11:00:00 │         19 │    -8 │\n",
      "│ 2023-12-01 14:23:00 │     7 │ 2023-12-01 14:00:00 │         10 │    -2 │\n",
      "│ 2023-12-01 15:22:00 │     6 │ 2023-12-01 15:00:00 │         10 │    -2 │\n",
      "│ 2023-12-01 15:41:00 │     9 │ 2023-12-01 15:00:00 │         10 │    -2 │\n",
      "│ 2023-12-02 10:21:00 │     9 │ 2023-12-02 10:00:00 │          8 │    -4 │\n",
      "│ 2023-12-02 11:01:00 │     5 │ 2023-12-02 11:00:00 │          8 │    -2 │\n",
      "│ 2023-12-02 12:23:00 │     7 │ 2023-12-02 12:00:00 │         10 │    -1 │\n",
      "│ 2023-12-02 13:06:00 │     8 │ 2023-12-02 13:00:00 │         10 │     0 │\n",
      "├─────────────────────┴───────┴─────────────────────┴────────────┴───────┤\n",
      "│ 10 rows                                                      5 columns │\n",
      "└────────────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select *\n",
    "    from scores as sc \n",
    "    asof join weather as w\n",
    "    on sc.score_time >= w.measurement_time\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ASOF JOIN connects each row in the scores table with the **nearest (or most recent)** value from the weather table, based on a score_time that is greater than or equal to the measurement_time in the weather table.  \n",
    "\n",
    "Under the hood, DuckDB used what is called a **\"fuzzy\" join**, joining on **values that may be close** (but not identical) across tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize bars in the output**\n",
    "\n",
    "There is a cool little function named bar that gives the visualization of bars that are proportional to the values of a column.  \n",
    "This means I can get bars that reflect the wind speed in a new column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────┬───────┬──────────────────────┬────────────┐\n",
      "│     score_time      │ score │    wind_bar_graph    │ wind_speed │\n",
      "│      timestamp      │ int64 │       varchar        │   int64    │\n",
      "├─────────────────────┼───────┼──────────────────────┼────────────┤\n",
      "│ 2023-12-01 10:01:00 │     8 │ ███████              │          7 │\n",
      "│ 2023-12-01 10:42:00 │     9 │ ███████              │          7 │\n",
      "│ 2023-12-01 11:24:00 │     4 │ ███████████████████  │         19 │\n",
      "│ 2023-12-01 14:23:00 │     7 │ ██████████           │         10 │\n",
      "│ 2023-12-01 15:22:00 │     6 │ ██████████           │         10 │\n",
      "│ 2023-12-01 15:41:00 │     9 │ ██████████           │         10 │\n",
      "│ 2023-12-02 10:21:00 │     9 │ ████████             │          8 │\n",
      "│ 2023-12-02 11:01:00 │     5 │ ████████             │          8 │\n",
      "│ 2023-12-02 12:23:00 │     7 │ ██████████           │         10 │\n",
      "│ 2023-12-02 13:06:00 │     8 │ ██████████           │         10 │\n",
      "├─────────────────────┴───────┴──────────────────────┴────────────┤\n",
      "│ 10 rows                                               4 columns │\n",
      "└─────────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "shell_commd(\n",
    "    \"\"\"\n",
    "    select \n",
    "        sc.*,\n",
    "        bar(\n",
    "            w.wind_speed, \n",
    "            0, 20, 20\n",
    "            )\n",
    "        as wind_bar_graph,\n",
    "        w.wind_speed\n",
    "    from scores\n",
    "        as sc asof join weather as w\n",
    "    on sc.score_time >= w.measurement_time\n",
    "    ;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clearly appears that the third skier faced a very strong wind. Maybe that's why he scored 4... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
